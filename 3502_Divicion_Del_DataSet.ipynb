{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49b78afa-6c50-4680-bd92-0f3c17896970",
   "metadata": {},
   "source": [
    "# Division del DataSet.\n",
    "\n",
    "En este notebook se muestran algunos de los mecanismos mas utlizados para la divicion del DataSet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8fe878-54cb-448a-9ee5-1a18060ce1a6",
   "metadata": {},
   "source": [
    "## DataSet\n",
    "\n",
    "### Descripcion:\n",
    "\n",
    "NSL-KDD is a data set suggested to solve some of the inherent problems of the KDD'99 data set which are mentioned in. Although, this new version of the KDD data set still suffers from some of the problems discussed by McHugh and may not be a perfect representative of existing real networks, because of the lack of public data sets for network-based IDSs, we believe it still can be applied as an effective benchmark data set to help researchers compare different intrusion detection methods. Furthermore, the number of records in the NSL-KDD train and test sets are reasonable. This advantage makes it affordable to run the experiments on the complete set without the need to randomly select a small portion. Consequently, evaluation results of different research work will be consistent and comparable.\n",
    "\n",
    "### Ficheros de datos\n",
    "* <span style=\"color:blue\">**KDDTrain+.ARFF:** The full NSL-KDD train set with binary labels in ARFF format</span>\n",
    "* KDDTrain+.TXT:** The full NSL-KDD train set including attack-type labels and difficulty level in CSV format\n",
    "* <span style=\"color:blue\">**KDDTrain+_20Percent.ARFF:** A 20% subset of the KDDTrain+.arff file</span>\n",
    "* <span style=\"color:blue\">**KDDTrain+_20Percent.TXT:** A 20% subset of the KDDTrain+.txt file</span>\n",
    "* <span style=\"color:blue\">**KDDTest+.ARFF:** The full NSL-KDD test set with binary labels in ARFF format</span>\n",
    "* <span style=\"color:blue\">**KDDTest+.TXT:** The full NSL-KDD test set including attack-type labels and difficulty level in CSV format</span>\n",
    "* <span style=\"color:blue\">**KDDTest-21.ARFF:** A subset of the KDDTest+.arff file which does not include records with difficulty level of 21 out of 21</span>\n",
    "* <span style=\"color:blue\">**KDDTest-21.TXT:** A subset of the KDDTest+.txt file which does not include records with difficulty level of 21 out of 21</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ca0e82-8cf0-4d31-8b46-a41e42c77267",
   "metadata": {},
   "source": [
    "# 1.- Lectura del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2f7a54-b985-44a6-a333-0d042c9b55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e7e50b-5e4f-483d-b3c4-5c2d5761afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kdd_dataset(data_path):\n",
    "    \"\"\"Lectura del DataSet NSL-KDD.\"\"\"\n",
    "    with open(data_path, 'r') as train_set:\n",
    "        dataset = arff.load(train_set)\n",
    "        \n",
    "    attributes = [attr[0] for attr in dataset[\"attributes\"]]\n",
    "    return pd.DataFrame(dataset[\"data\"], columns = attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6405185-0959-48e7-ac46-f7f5ae94f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_kdd_dataset('datasets/datasets/NSL-KDD/KDDTrain+.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e1ab723-8186-4236-91c0-c69dcba4f61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125973 entries, 0 to 125972\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   duration                     125973 non-null  float64\n",
      " 1   protocol_type                125973 non-null  object \n",
      " 2   service                      125973 non-null  object \n",
      " 3   flag                         125973 non-null  object \n",
      " 4   src_bytes                    125973 non-null  float64\n",
      " 5   dst_bytes                    125973 non-null  float64\n",
      " 6   land                         125973 non-null  object \n",
      " 7   wrong_fragment               125973 non-null  float64\n",
      " 8   urgent                       125973 non-null  float64\n",
      " 9   hot                          125973 non-null  float64\n",
      " 10  num_failed_logins            125973 non-null  float64\n",
      " 11  logged_in                    125973 non-null  object \n",
      " 12  num_compromised              125973 non-null  float64\n",
      " 13  root_shell                   125973 non-null  float64\n",
      " 14  su_attempted                 125973 non-null  float64\n",
      " 15  num_root                     125973 non-null  float64\n",
      " 16  num_file_creations           125973 non-null  float64\n",
      " 17  num_shells                   125973 non-null  float64\n",
      " 18  num_access_files             125973 non-null  float64\n",
      " 19  num_outbound_cmds            125973 non-null  float64\n",
      " 20  is_host_login                125973 non-null  object \n",
      " 21  is_guest_login               125973 non-null  object \n",
      " 22  count                        125973 non-null  float64\n",
      " 23  srv_count                    125973 non-null  float64\n",
      " 24  serror_rate                  125973 non-null  float64\n",
      " 25  srv_serror_rate              125973 non-null  float64\n",
      " 26  rerror_rate                  125973 non-null  float64\n",
      " 27  srv_rerror_rate              125973 non-null  float64\n",
      " 28  same_srv_rate                125973 non-null  float64\n",
      " 29  diff_srv_rate                125973 non-null  float64\n",
      " 30  srv_diff_host_rate           125973 non-null  float64\n",
      " 31  dst_host_count               125973 non-null  float64\n",
      " 32  dst_host_srv_count           125973 non-null  float64\n",
      " 33  dst_host_same_srv_rate       125973 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       125973 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  125973 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  125973 non-null  float64\n",
      " 37  dst_host_serror_rate         125973 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     125973 non-null  float64\n",
      " 39  dst_host_rerror_rate         125973 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     125973 non-null  float64\n",
      " 41  class                        125973 non-null  object \n",
      "dtypes: float64(34), object(8)\n",
      "memory usage: 40.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8788c5e-b9a0-4d68-9252-ff7685e0434b",
   "metadata": {},
   "source": [
    "# 2.- Division del DataSet\n",
    "\n",
    "Se debe Separ el DataSet en los difentes subconjuntos necesarios para realizar los procesos de entrenamiento, de validacion y pruebas\n",
    "sklearn tiene implementada la funsion **split_train_test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "054f45a7-540e-4893-952d-3de3ed91448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar el dataSet de datos, 60% train_set, 40%t est_set\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "train_set, test_set = train_test_split(df, test_size =0.4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1db129d-cbb2-4ecd-8f51-57bf4883951a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 75583 entries, 98320 to 121958\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   duration                     75583 non-null  float64\n",
      " 1   protocol_type                75583 non-null  object \n",
      " 2   service                      75583 non-null  object \n",
      " 3   flag                         75583 non-null  object \n",
      " 4   src_bytes                    75583 non-null  float64\n",
      " 5   dst_bytes                    75583 non-null  float64\n",
      " 6   land                         75583 non-null  object \n",
      " 7   wrong_fragment               75583 non-null  float64\n",
      " 8   urgent                       75583 non-null  float64\n",
      " 9   hot                          75583 non-null  float64\n",
      " 10  num_failed_logins            75583 non-null  float64\n",
      " 11  logged_in                    75583 non-null  object \n",
      " 12  num_compromised              75583 non-null  float64\n",
      " 13  root_shell                   75583 non-null  float64\n",
      " 14  su_attempted                 75583 non-null  float64\n",
      " 15  num_root                     75583 non-null  float64\n",
      " 16  num_file_creations           75583 non-null  float64\n",
      " 17  num_shells                   75583 non-null  float64\n",
      " 18  num_access_files             75583 non-null  float64\n",
      " 19  num_outbound_cmds            75583 non-null  float64\n",
      " 20  is_host_login                75583 non-null  object \n",
      " 21  is_guest_login               75583 non-null  object \n",
      " 22  count                        75583 non-null  float64\n",
      " 23  srv_count                    75583 non-null  float64\n",
      " 24  serror_rate                  75583 non-null  float64\n",
      " 25  srv_serror_rate              75583 non-null  float64\n",
      " 26  rerror_rate                  75583 non-null  float64\n",
      " 27  srv_rerror_rate              75583 non-null  float64\n",
      " 28  same_srv_rate                75583 non-null  float64\n",
      " 29  diff_srv_rate                75583 non-null  float64\n",
      " 30  srv_diff_host_rate           75583 non-null  float64\n",
      " 31  dst_host_count               75583 non-null  float64\n",
      " 32  dst_host_srv_count           75583 non-null  float64\n",
      " 33  dst_host_same_srv_rate       75583 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       75583 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  75583 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  75583 non-null  float64\n",
      " 37  dst_host_serror_rate         75583 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     75583 non-null  float64\n",
      " 39  dst_host_rerror_rate         75583 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     75583 non-null  float64\n",
      " 41  class                        75583 non-null  object \n",
      "dtypes: float64(34), object(8)\n",
      "memory usage: 24.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#40% datos\n",
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e80bc75b-2861-4b00-b249-69c6da1c6dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50390 entries, 378 to 89600\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   duration                     50390 non-null  float64\n",
      " 1   protocol_type                50390 non-null  object \n",
      " 2   service                      50390 non-null  object \n",
      " 3   flag                         50390 non-null  object \n",
      " 4   src_bytes                    50390 non-null  float64\n",
      " 5   dst_bytes                    50390 non-null  float64\n",
      " 6   land                         50390 non-null  object \n",
      " 7   wrong_fragment               50390 non-null  float64\n",
      " 8   urgent                       50390 non-null  float64\n",
      " 9   hot                          50390 non-null  float64\n",
      " 10  num_failed_logins            50390 non-null  float64\n",
      " 11  logged_in                    50390 non-null  object \n",
      " 12  num_compromised              50390 non-null  float64\n",
      " 13  root_shell                   50390 non-null  float64\n",
      " 14  su_attempted                 50390 non-null  float64\n",
      " 15  num_root                     50390 non-null  float64\n",
      " 16  num_file_creations           50390 non-null  float64\n",
      " 17  num_shells                   50390 non-null  float64\n",
      " 18  num_access_files             50390 non-null  float64\n",
      " 19  num_outbound_cmds            50390 non-null  float64\n",
      " 20  is_host_login                50390 non-null  object \n",
      " 21  is_guest_login               50390 non-null  object \n",
      " 22  count                        50390 non-null  float64\n",
      " 23  srv_count                    50390 non-null  float64\n",
      " 24  serror_rate                  50390 non-null  float64\n",
      " 25  srv_serror_rate              50390 non-null  float64\n",
      " 26  rerror_rate                  50390 non-null  float64\n",
      " 27  srv_rerror_rate              50390 non-null  float64\n",
      " 28  same_srv_rate                50390 non-null  float64\n",
      " 29  diff_srv_rate                50390 non-null  float64\n",
      " 30  srv_diff_host_rate           50390 non-null  float64\n",
      " 31  dst_host_count               50390 non-null  float64\n",
      " 32  dst_host_srv_count           50390 non-null  float64\n",
      " 33  dst_host_same_srv_rate       50390 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       50390 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  50390 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  50390 non-null  float64\n",
      " 37  dst_host_serror_rate         50390 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     50390 non-null  float64\n",
      " 39  dst_host_rerror_rate         50390 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     50390 non-null  float64\n",
      " 41  class                        50390 non-null  object \n",
      "dtypes: float64(34), object(8)\n",
      "memory usage: 16.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#60% de datos\n",
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7ef9467-4d59-4c4a-bd63-b0197d9d4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar el conjunto o el DataSet de pruebas 50% validation_set 50% test_set\n",
    "val_set, test_set = train_test_split(test_set, test_size = 0.5, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d41fade9-3ddd-4a88-bf80-a8b1c923e35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del training_set 75583\n",
      "Longitud de validation_set 25195\n",
      "Longitud del Test_set 25195\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitud del training_set\", len(train_set))\n",
    "print(\"Longitud de validation_set\", len(val_set))\n",
    "print (\"Longitud del Test_set\", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb8802-56ec-4aea-8854-4770ec01d36e",
   "metadata": {},
   "source": [
    "# 3.- Particionado y aleatorio y Stratified Sampling\n",
    "\n",
    "Sklearn implementa la funsion **train_test_split**, sin embargo esta funsion por defecto realiza un particionado del dataset aleatorio para cada vez que se ejecuta el script. Aun anadiendo una semilla fija para la generacion aleatorea cada vez que se carge de nuevo el DataSet se generara nuevos subconjuntos esto puede ocacionar que despues de muchos intentos, el algoritmo \"vea o conozca todo el DataSet\".\n",
    "\n",
    "para solucionar este stopper, Sklearn ha implementado **shuffle** en la funsion **train_test_split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd7e67d2-5814-4ab9-926e-2c31cf9c1b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si shuffle = false, el DataSet no mezclara antes el particionado.\n",
    "train_set, test_set = train_test_split(df, test_size =0.40, random_state =42, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f272557-64ad-4c84-8c3b-9e463a037f17",
   "metadata": {},
   "source": [
    " Estos metodos de division del DataSet estan bien si se tiene un DataSet muy grande, pero si no se tiene se corre el resgo de introducir **\"Sampling bias\"**. \n",
    "\n",
    " Para evitar esto, se utiliza un metodo de **Sampling** que se llama **stratify sampling**. El objetivo es que no quede nimguna caracteristica del DataSet sin representacion en ninguno de los subconjuntos de datos para una o mas caracteristicas en particular.\n",
    "\n",
    " Sklearn introduce el parametro **stratify** en la funsion **train_test_split** para controlar este comportamiento en particular.\n",
    "\n",
    " This **stratify** parameter makes a split so that the proportition of values in the sampleproducer will be same as the proportion of make sure that your random split has 25% of 0's and 75% 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50a50175-9843-4d06-80d9-147da3aacb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set ,test_set = train_test_split(df, test_size = 0.4, random_state = 42, stratify = df[\"protocol_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad3ac3-d461-49cd-9a1c-b5747a8bdd51",
   "metadata": {},
   "source": [
    "# 4.- generacion de una funsion de particionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48f9d814-fd73-4d51-8109-8c61e9f73619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construccion de una funsion que realize el particionado completo \n",
    "def train_val_test_split(df, rstate = 42, shuffle = True, stratify = None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "        df, test_size = 0.4, random_state = rstate, shuffle = shuffle, stratify = strat)\n",
    "    \n",
    "    strat = test_set [stratify] if stratify else None\n",
    "    val_set = test_set = train_test_split(\n",
    "        test_set, test_size = 0.5, random_state = rstate, shuffle = shuffle, stratify = strat)\n",
    "    \n",
    "    return (train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcfd823f-9a5a-4252-8edf-b873be304f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitud de Set de datos 125973\n"
     ]
    }
   ],
   "source": [
    "print (\"longitud de Set de datos\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ff1596b-a67c-449d-85e4-81fd79580769",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = train_val_test_split(df, stratify = 'protocol_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "524e7154-09fe-432f-81d6-5e1a2c0d0177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del training_set 75583\n",
      "Longitud de validation_set 2\n",
      "Longitud del Test_set 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitud del training_set\", len(train_set))\n",
    "print(\"Longitud de validation_set\", len(val_set))\n",
    "print (\"Longitud del Test_set\", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80681675-129a-420b-af9e-7bcae63da30c",
   "metadata": {},
   "source": [
    "#\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "df[\"protocol_type\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9679d5fe-8427-44cb-858a-574d94d6ac6f",
   "metadata": {},
   "source": [
    "train_set[\"protocol_type\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bba104-c013-4e88-8e15-8f5759b50e51",
   "metadata": {},
   "source": [
    "val_set[\"protocol_type\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfcfcae-6086-4aa2-b165-d5afd5679c47",
   "metadata": {},
   "source": [
    "test_set[\"protocol_type\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3347a6-23f3-4ccd-b39a-1168bb210a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
